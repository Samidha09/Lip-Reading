{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import keras \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image \n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "import dlib\n",
    "import cv2\n",
    "import easydict\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.regularizers import l2\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "lip_data = np.load('all_words.npy')\n",
    "lip_labels = np.load('all_words_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_hot=to_categorical(lip_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(lip_data,labels_hot,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200, 10, 20), (1200, 10), (300, 10, 20), (300, 10))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.LSTM(200,activation='tanh', return_sequences=True,input_shape=(10,20)))\n",
    "model.add(layers.LSTM(150,activation='tanh', return_sequences=True))\n",
    "model.add(layers.LSTM(100,activation='tanh', return_sequences=True))\n",
    "model.add(layers.LSTM(80,activation='tanh'))\n",
    "model.add(layers.Dense(10,activation=\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Nadam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1200 samples, validate on 300 samples\n",
      "Epoch 1/100\n",
      "1200/1200 [==============================] - 54s 45ms/step - loss: 2.2245 - acc: 0.1567 - val_loss: 2.0843 - val_acc: 0.2200\n",
      "Epoch 2/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 2.0609 - acc: 0.2217 - val_loss: 2.1393 - val_acc: 0.2167\n",
      "Epoch 3/100\n",
      "1200/1200 [==============================] - 14s 12ms/step - loss: 1.9442 - acc: 0.2683 - val_loss: 1.9462 - val_acc: 0.2733\n",
      "Epoch 4/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 1.8711 - acc: 0.2900 - val_loss: 1.8335 - val_acc: 0.2633\n",
      "Epoch 5/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 1.7871 - acc: 0.3383 - val_loss: 1.8804 - val_acc: 0.2700\n",
      "Epoch 6/100\n",
      "1200/1200 [==============================] - 16s 13ms/step - loss: 1.7211 - acc: 0.3525 - val_loss: 1.7572 - val_acc: 0.3200\n",
      "Epoch 7/100\n",
      "1200/1200 [==============================] - 14s 12ms/step - loss: 1.6601 - acc: 0.3792 - val_loss: 1.6276 - val_acc: 0.4133\n",
      "Epoch 8/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 1.5584 - acc: 0.4317 - val_loss: 1.7513 - val_acc: 0.3400\n",
      "Epoch 9/100\n",
      "1200/1200 [==============================] - 14s 12ms/step - loss: 1.4870 - acc: 0.4508 - val_loss: 1.5494 - val_acc: 0.4000\n",
      "Epoch 10/100\n",
      "1200/1200 [==============================] - 14s 12ms/step - loss: 1.4107 - acc: 0.4700 - val_loss: 1.8184 - val_acc: 0.3633\n",
      "Epoch 11/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 1.3531 - acc: 0.4917 - val_loss: 1.5792 - val_acc: 0.4100\n",
      "Epoch 12/100\n",
      "1200/1200 [==============================] - 13s 10ms/step - loss: 1.2856 - acc: 0.5225 - val_loss: 1.4314 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 1.1760 - acc: 0.5792 - val_loss: 1.3967 - val_acc: 0.4833\n",
      "Epoch 14/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 1.0585 - acc: 0.6142 - val_loss: 1.3214 - val_acc: 0.5433\n",
      "Epoch 15/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.9628 - acc: 0.6625 - val_loss: 1.3643 - val_acc: 0.5133\n",
      "Epoch 16/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.8901 - acc: 0.6933 - val_loss: 1.3678 - val_acc: 0.5367\n",
      "Epoch 17/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.8333 - acc: 0.7000 - val_loss: 1.2183 - val_acc: 0.5933\n",
      "Epoch 18/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.7621 - acc: 0.7367 - val_loss: 1.2631 - val_acc: 0.5633\n",
      "Epoch 19/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.6666 - acc: 0.7675 - val_loss: 1.2708 - val_acc: 0.5867\n",
      "Epoch 20/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.5911 - acc: 0.8000 - val_loss: 1.1282 - val_acc: 0.6233\n",
      "Epoch 21/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.5081 - acc: 0.8350 - val_loss: 1.2248 - val_acc: 0.5967\n",
      "Epoch 22/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.4669 - acc: 0.8425 - val_loss: 1.2523 - val_acc: 0.6033\n",
      "Epoch 23/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.3340 - acc: 0.8967 - val_loss: 1.2340 - val_acc: 0.6100\n",
      "Epoch 24/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.3282 - acc: 0.8900 - val_loss: 1.3377 - val_acc: 0.5867\n",
      "Epoch 25/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.2636 - acc: 0.9175 - val_loss: 1.2396 - val_acc: 0.6433\n",
      "Epoch 26/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.2129 - acc: 0.9308 - val_loss: 1.3331 - val_acc: 0.6067\n",
      "Epoch 27/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.2341 - acc: 0.9225 - val_loss: 1.3669 - val_acc: 0.6333\n",
      "Epoch 28/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.1731 - acc: 0.9533 - val_loss: 1.1741 - val_acc: 0.6467\n",
      "Epoch 29/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.2210 - acc: 0.9333 - val_loss: 1.3162 - val_acc: 0.6100\n",
      "Epoch 30/100\n",
      "1200/1200 [==============================] - 13s 10ms/step - loss: 0.1555 - acc: 0.9525 - val_loss: 1.3539 - val_acc: 0.6333\n",
      "Epoch 31/100\n",
      "1200/1200 [==============================] - 13s 10ms/step - loss: 0.1203 - acc: 0.9667 - val_loss: 1.2932 - val_acc: 0.6233\n",
      "Epoch 32/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0813 - acc: 0.9800 - val_loss: 1.3831 - val_acc: 0.6500\n",
      "Epoch 33/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0356 - acc: 0.9958 - val_loss: 1.3560 - val_acc: 0.6533\n",
      "Epoch 34/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0181 - acc: 0.9992 - val_loss: 1.3395 - val_acc: 0.6633\n",
      "Epoch 35/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0128 - acc: 0.9992 - val_loss: 1.3793 - val_acc: 0.6467\n",
      "Epoch 36/100\n",
      "1200/1200 [==============================] - 13s 10ms/step - loss: 0.0571 - acc: 0.9833 - val_loss: 1.4670 - val_acc: 0.6600\n",
      "Epoch 37/100\n",
      "1200/1200 [==============================] - 13s 10ms/step - loss: 0.0603 - acc: 0.9883 - val_loss: 1.7073 - val_acc: 0.6367\n",
      "Epoch 38/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.3688 - acc: 0.8825 - val_loss: 1.5719 - val_acc: 0.5833\n",
      "Epoch 39/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.1927 - acc: 0.9483 - val_loss: 1.5649 - val_acc: 0.5967\n",
      "Epoch 40/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0862 - acc: 0.9800 - val_loss: 1.4890 - val_acc: 0.6333\n",
      "Epoch 41/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0472 - acc: 0.9900 - val_loss: 1.3990 - val_acc: 0.6767\n",
      "Epoch 42/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 1.4019 - val_acc: 0.6833\n",
      "Epoch 43/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.4133 - val_acc: 0.6767\n",
      "Epoch 44/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 1.4336 - val_acc: 0.6733\n",
      "Epoch 45/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 1.4524 - val_acc: 0.6800\n",
      "Epoch 46/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 1.4584 - val_acc: 0.6800\n",
      "Epoch 47/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 1.4730 - val_acc: 0.6800\n",
      "Epoch 48/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 1.4795 - val_acc: 0.6767\n",
      "Epoch 49/100\n",
      "1200/1200 [==============================] - 15s 13ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 1.4930 - val_acc: 0.6767\n",
      "Epoch 50/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 1.5033 - val_acc: 0.6767\n",
      "Epoch 51/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 1.5142 - val_acc: 0.6800\n",
      "Epoch 52/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 1.5219 - val_acc: 0.6767\n",
      "Epoch 53/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 1.5302 - val_acc: 0.6800\n",
      "Epoch 54/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 1.5432 - val_acc: 0.6733\n",
      "Epoch 55/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 1.5479 - val_acc: 0.6767\n",
      "Epoch 56/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 1.5548 - val_acc: 0.6767\n",
      "Epoch 57/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 1.5630 - val_acc: 0.6733\n",
      "Epoch 58/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.5652 - val_acc: 0.6800\n",
      "Epoch 59/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 1.5783 - val_acc: 0.6733\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 1.5823 - val_acc: 0.6767\n",
      "Epoch 61/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 1.5949 - val_acc: 0.6767\n",
      "Epoch 62/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.5980 - val_acc: 0.6733\n",
      "Epoch 63/100\n",
      "1200/1200 [==============================] - 14s 11ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 1.6049 - val_acc: 0.6767\n",
      "Epoch 64/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 1.6088 - val_acc: 0.6800\n",
      "Epoch 65/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 1.6176 - val_acc: 0.6833\n",
      "Epoch 66/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 9.9298e-04 - acc: 1.0000 - val_loss: 1.6232 - val_acc: 0.6900\n",
      "Epoch 67/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 9.4440e-04 - acc: 1.0000 - val_loss: 1.6300 - val_acc: 0.6867\n",
      "Epoch 68/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 8.9905e-04 - acc: 1.0000 - val_loss: 1.6379 - val_acc: 0.6900\n",
      "Epoch 69/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 8.5662e-04 - acc: 1.0000 - val_loss: 1.6412 - val_acc: 0.6867\n",
      "Epoch 70/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 8.1698e-04 - acc: 1.0000 - val_loss: 1.6486 - val_acc: 0.6867\n",
      "Epoch 71/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 7.8007e-04 - acc: 1.0000 - val_loss: 1.6557 - val_acc: 0.6833\n",
      "Epoch 72/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 7.4442e-04 - acc: 1.0000 - val_loss: 1.6612 - val_acc: 0.6767\n",
      "Epoch 73/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 7.1173e-04 - acc: 1.0000 - val_loss: 1.6693 - val_acc: 0.6800\n",
      "Epoch 74/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 6.8050e-04 - acc: 1.0000 - val_loss: 1.6733 - val_acc: 0.6767\n",
      "Epoch 75/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 6.5133e-04 - acc: 1.0000 - val_loss: 1.6754 - val_acc: 0.6767\n",
      "Epoch 76/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 6.2379e-04 - acc: 1.0000 - val_loss: 1.6813 - val_acc: 0.6833\n",
      "Epoch 77/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 5.9778e-04 - acc: 1.0000 - val_loss: 1.6883 - val_acc: 0.6800\n",
      "Epoch 78/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 5.7211e-04 - acc: 1.0000 - val_loss: 1.6941 - val_acc: 0.6800\n",
      "Epoch 79/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 5.4904e-04 - acc: 1.0000 - val_loss: 1.7003 - val_acc: 0.6833\n",
      "Epoch 80/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 5.2661e-04 - acc: 1.0000 - val_loss: 1.7041 - val_acc: 0.6800\n",
      "Epoch 81/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 5.0507e-04 - acc: 1.0000 - val_loss: 1.7084 - val_acc: 0.6800\n",
      "Epoch 82/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 4.8497e-04 - acc: 1.0000 - val_loss: 1.7146 - val_acc: 0.6833\n",
      "Epoch 83/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 4.6566e-04 - acc: 1.0000 - val_loss: 1.7190 - val_acc: 0.6800\n",
      "Epoch 84/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 4.4740e-04 - acc: 1.0000 - val_loss: 1.7253 - val_acc: 0.6800\n",
      "Epoch 85/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 4.2996e-04 - acc: 1.0000 - val_loss: 1.7281 - val_acc: 0.6833\n",
      "Epoch 86/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 4.1353e-04 - acc: 1.0000 - val_loss: 1.7370 - val_acc: 0.6833\n",
      "Epoch 87/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 3.9739e-04 - acc: 1.0000 - val_loss: 1.7411 - val_acc: 0.6800\n",
      "Epoch 88/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 3.8224e-04 - acc: 1.0000 - val_loss: 1.7423 - val_acc: 0.6833\n",
      "Epoch 89/100\n",
      "1200/1200 [==============================] - 14s 12ms/step - loss: 3.6756e-04 - acc: 1.0000 - val_loss: 1.7510 - val_acc: 0.6800\n",
      "Epoch 90/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 3.5392e-04 - acc: 1.0000 - val_loss: 1.7518 - val_acc: 0.6833\n",
      "Epoch 91/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 3.4083e-04 - acc: 1.0000 - val_loss: 1.7579 - val_acc: 0.6833\n",
      "Epoch 92/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 3.2797e-04 - acc: 1.0000 - val_loss: 1.7641 - val_acc: 0.6800\n",
      "Epoch 93/100\n",
      "1200/1200 [==============================] - 13s 10ms/step - loss: 3.1572e-04 - acc: 1.0000 - val_loss: 1.7679 - val_acc: 0.6833\n",
      "Epoch 94/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 3.0407e-04 - acc: 1.0000 - val_loss: 1.7705 - val_acc: 0.6833\n",
      "Epoch 95/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 2.9287e-04 - acc: 1.0000 - val_loss: 1.7742 - val_acc: 0.6833\n",
      "Epoch 96/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 2.8231e-04 - acc: 1.0000 - val_loss: 1.7818 - val_acc: 0.6800\n",
      "Epoch 97/100\n",
      "1200/1200 [==============================] - 13s 11ms/step - loss: 2.7198e-04 - acc: 1.0000 - val_loss: 1.7869 - val_acc: 0.6767\n",
      "Epoch 98/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 2.6228e-04 - acc: 1.0000 - val_loss: 1.7918 - val_acc: 0.6800\n",
      "Epoch 99/100\n",
      "1200/1200 [==============================] - 12s 10ms/step - loss: 2.5266e-04 - acc: 1.0000 - val_loss: 1.7972 - val_acc: 0.6767\n",
      "Epoch 100/100\n",
      "1200/1200 [==============================] - 13s 10ms/step - loss: 2.4361e-04 - acc: 1.0000 - val_loss: 1.8026 - val_acc: 0.6800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eb22a0ca20>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,batch_size=20, epochs=100,validation_data=(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_85 (LSTM)               (None, 10, 200)           176800    \n",
      "_________________________________________________________________\n",
      "lstm_86 (LSTM)               (None, 10, 150)           210600    \n",
      "_________________________________________________________________\n",
      "lstm_87 (LSTM)               (None, 10, 100)           100400    \n",
      "_________________________________________________________________\n",
      "lstm_88 (LSTM)               (None, 80)                57920     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                810       \n",
      "=================================================================\n",
      "Total params: 546,530\n",
      "Trainable params: 546,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.array(pred)\n",
    "approximate_predictions = []\n",
    "for i in range(pred.shape[0]):\n",
    "    val_class = np.argmax(pred[i])\n",
    "    approximate_predictions.append(val_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = np.array(Y_test)\n",
    "correct_predictions = []\n",
    "for i in range(correct_pred.shape[0]):\n",
    "    val_class = np.argmax(correct_pred[i])\n",
    "    correct_predictions.append(val_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "total = 0\n",
    "for i in range(len(correct_predictions)):\n",
    "    if(correct_predictions[i] == approximate_predictions[i]):\n",
    "        count += 1\n",
    "    total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.66666666666667\n"
     ]
    }
   ],
   "source": [
    "accuracy = (count*100/total)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['BEGIN','CHOOSE','CONNECTION','NAVIGATION','NEXT','PREVIOUS','START','STOP','HELLO','WEB']\n",
    "#phrases = ['STOP NAVIGATION.','EXCUSE ME.','I AM SORRY.','THANK YOU.','GOOD BYE.','I LOVE THIS GAME.','NICE TO MEET YOU.','YOU ARE WELCOME.','HOW ARE YOU?','HAVE A GOOD TIME.']\n",
    "dict = {}\n",
    "'''for i in range(10):\n",
    "        dict[i] = phrases[i]'''\n",
    "for i in range(10):\n",
    "        dict[i] = words[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for i in range(len(approximate_predictions)):\n",
    "    outputs.append(dict[approximate_predictions[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('minor3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
